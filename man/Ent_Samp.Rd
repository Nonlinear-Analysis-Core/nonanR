% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{Ent_Samp}
\alias{Ent_Samp}
\title{Sample Entropy}
\usage{
Ent_Samp(x, m, R)
}
\arguments{
\item{x}{A single column time series}

\item{m}{The length of the vectors to be compared for matches}

\item{R}{The radius for accepting matches}
}
\value{
The output of the algorithm is a single value that reflects the entropy of the time series in bits.
}
\description{
Calculate the sample entropy of a time series.
}
\details{
Sample entropy is another of the entropy algorithms that aims to quantify the predictability of a time series. Originally developed by Richman and Moorman, sample entropy is an improvement on approximate entropy, designed to overcome the lack of consistency seen in physiological time series and to reduce the bias introduced by self-matches.

Sample entropy captures the predictability of the time series by taking the negative natural log of the conditional probability that two sequences similar for the first \eqn{m} points remain similar at the next point, within a given tolerance \eqn{r}. Unlike ApEn, SampEn does not include self-matches in this probability calculation, which helps reduce bias and dependency on the length of the time series. The full equation is as follows: 

\eqn{SE = -ln(\frac{A}{B})}

where \eqn{A} is the number of matching vectors of length \eqn{m +1} and \eqn{B} is the number of matching vectors of length m.

Like approximate entropy, sample entropy is measured in bits where lower bits (information content) indicates more predictably thus, a larger value would indicate more randomness and less predictability. While sample entropy is more robust to shorter time series and parameter selections, these things should always be kept in mind for analysis. Best practice is to use a range of parameter values as different values may reveal different results.
}
\examples{

x = rnorm(1000)
m = 2
R = 0.2

SE = Ent_Samp(x, m, R)

}
\references{
Richman, J.S., Moorman, J.R., 2000. Physiological time-series analysis using approximate entropy and sample entropy. Am. J. Physiol. Heart Circ. Physiol. 278. https://doi.org/10.1152/ajpheart.2000.278.6.H2039
}
